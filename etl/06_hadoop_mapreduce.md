## General Description
- Hadoop MapReduce is a software framework for easily writing applications which process vast amounts of data in parallel on large clusters of commodity hardware in a reliable, fault-tolerant manner
- A MapReduce job usually splits the raw input dataset into independent chunks for processing
- This processing is made up of two phases:
	1. A map function
		- 

## References
- https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html
- https://www.guru99.com/introduction-to-mapreduce.html
- https://www.slideshare.net/cloudera/introduction-to-yarn-and-mapreduce-2
